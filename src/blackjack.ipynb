{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from blackjackenv_extended import BlackjackEnv\n",
    "from random_agent import RandomAgent\n",
    "from basic_strategy_agent import BasicStrategyAgent\n",
    "from backprop_agent import BackpropAgent\n",
    "from FFNN_agent import FFNNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = {0: 'STAND', 1:'HIT', 2:'DOUBLE', 3: 'SPLIT'}\n",
    "\n",
    "rewards = []\n",
    "\n",
    "def play_game(env, episodes, agent, collect_data=False):\n",
    "\n",
    "    for episode in tqdm(range(episodes)):\n",
    "        observation, info = env.reset()\n",
    "        done = False\n",
    "        \n",
    "        # print(\"hand 1\", env.player)\n",
    "        # print(\"hand 2\", env.player2)\n",
    "        # print(\"Start Observation: \", observation)\n",
    "        \n",
    "        \n",
    "        while not done:\n",
    "            \n",
    "            action = agent.get_action(observation)\n",
    "            # print(\"Action: \", KEY[action])\n",
    "\n",
    "            # save data for training\n",
    "            if collect_data:\n",
    "                agent.collect_data(observation, action)\n",
    "            \n",
    "            observation, reward, terminated, truncated, info = env.step(action) \n",
    "            # print(\"hand 1\", env.player)\n",
    "            # print(\"hand 2\", env.player2)\n",
    "            # print(\"Observation: \", observation, \"Reward: \", reward)\n",
    "            \n",
    "\n",
    "            if terminated or truncated:\n",
    "                # print(f\"Dealer hand: \", env.dealer)\n",
    "                rewards.append(reward)\n",
    "                observation = env.reset()\n",
    "                done = True\n",
    "            \n",
    "\n",
    "    if collect_data:\n",
    "        agent.save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"using gpu: \", torch.cuda.get_device_name())\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"using cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 393.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reward:  -0.4\n",
      "Variance:  2.266666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "env = BlackjackEnv(natural=True)\n",
    "\n",
    "# Hyperparameters\n",
    "episodes = 10\n",
    "collect_data = True\n",
    "\n",
    "\n",
    "#agent = RandomAgent(env, filename=\"random_agent\")\n",
    "#agent = BasicStrategyAgent(env, filename=\"basic_strategy_agent\")\n",
    "# agent = BackpropAgent(env, \n",
    "#                       model=torch.load('../models/backprop_model.pth'),\n",
    "#                       input_size=5, \n",
    "#                       output_size=4, \n",
    "#                       hidden_size=30, \n",
    "#                       activation_fn=nn.ReLU(),\n",
    "#                       filename=\"backprop_agent\"\n",
    "#                     )\n",
    "agent = FFNNAgent(env,\n",
    "                  model_path='../models/best_model.pth',\n",
    "                  device=device,\n",
    "                  layers=[9,30,30],\n",
    "                  threshold=0.5,\n",
    "                  lr=0.01,\n",
    "                  filename=\"ffnn_agent\"\n",
    "                  )\n",
    "\n",
    "rewards = []\n",
    "\n",
    "play_game(env, episodes, agent, collect_data)\n",
    "\n",
    "average_reward = sum(rewards)/episodes\n",
    "variance = sum([((x - average_reward) ** 2) for x in rewards]) / (episodes - 1)\n",
    "\n",
    "#print(\"Rewards: \", rewards)\n",
    "print(\"Average Reward: \", average_reward)\n",
    "print(\"Variance: \", variance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
